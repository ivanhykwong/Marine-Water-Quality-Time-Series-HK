{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and load libraries for image processing steps\n",
    "# pip install --user landsatxplore-master.zip\n",
    "from landsatxplore.api import API\n",
    "from landsatxplore.earthexplorer import EarthExplorer\n",
    "import os\n",
    "import shutil\n",
    "from datetime import date, datetime, timedelta\n",
    "import zipfile\n",
    "import tarfile \n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from simpledbf import Dbf5\n",
    "import requests\n",
    "import arcpy\n",
    "from arcpy import env\n",
    "from arcpy.sa import *\n",
    "arcpy.CheckOutExtension(\"spatial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search and download Landsat satellite images\n",
    "def downloadlandsat(startdate, enddate):\n",
    "    # Initialize a new API instance and get an access key\n",
    "    username = \"username\"  # change your EarthExplorer username and password\n",
    "    password = \"password\"\n",
    "    api = API(username, password)\n",
    "    # 22.13,113.81,22.59,114.52\n",
    "    # https://github.com/yannforget/landsatxplore/blob/master/landsatxplore/api.py\n",
    "    # Search for Landsat TM scenes\n",
    "    scenes = api.search(\n",
    "        dataset='landsat_ot_c2_l1', bbox=(113.81, 22.13, 114.52, 22.59),\n",
    "        start_date=startdate,  # start_date='2014-01-01',\n",
    "        end_date=enddate,   # end_date='2015-12-31',\n",
    "        max_cloud_cover=20, max_results=1000\n",
    "    )\n",
    "    print(f\"{len(scenes)} Landsat scenes found.\")\n",
    "    print(scenes)\n",
    "    # Log out\n",
    "    api.logout()\n",
    "    # Downloading scenes\n",
    "    if len(scenes) > 0:\n",
    "        ee = EarthExplorer(username, password)\n",
    "        df = pd.read_csv(\"D:/WaterQuality/ImageInfo.csv\")\n",
    "        for s in scenes:\n",
    "            print(s['landsat_product_id'])\n",
    "            ee.download(s['entity_id'], output_dir='D:/WaterQuality/datadownload')\n",
    "            df.loc[len(df.index)] = [s['landsat_product_id'], s['start_time'].isoformat()]\n",
    "        df.to_csv(\"D:/WaterQuality/ImageInfo.csv\", index=False)\n",
    "        ee.logout()\n",
    "\n",
    "# Search and download Sentinel satellite images\n",
    "def downloadsentinel(startdate, enddate):\n",
    "    # WKT Representation of BBOX of AOI\n",
    "    ft = \"POLYGON((113.81 22.13, 114.52 22.13, 114.52 22.59, 113.81 22.59, 113.81 22.13))\" \n",
    "    data_collection = \"SENTINEL-2\"\n",
    "\n",
    "    def get_keycloak():\n",
    "        data = {\n",
    "            \"client_id\": \"cdse-public\",\n",
    "            \"username\": \"username\",  # change your copernicus dataspace username and password\n",
    "            \"password\": \"password\",\n",
    "            \"grant_type\": \"password\",\n",
    "        }\n",
    "        try:\n",
    "            r = requests.post(\n",
    "                \"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\",\n",
    "                data=data,\n",
    "            )\n",
    "            r.raise_for_status()\n",
    "        except Exception as e:\n",
    "            raise Exception(\n",
    "                f\"Keycloak token creation failed. Reponse from the server was: {r.json()}\"\n",
    "            )\n",
    "        return r.json()[\"access_token\"]\n",
    "    \n",
    "    json_ = requests.get(  # cloud le 20\n",
    "        f\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq '{data_collection}' and OData.CSC.Intersects(area=geography'SRID=4326;{ft}') and Attributes/OData.CSC.DoubleAttribute/any(att:att/Name eq 'cloudCover' and att/OData.CSC.DoubleAttribute/Value le 20.00) and ContentDate/Start gt {startdate}T00:00:00.000Z and ContentDate/Start lt {enddate}T23:59:00.000Z&$count=True&$top=1000\"\n",
    "    ).json()\n",
    "    p = pd.DataFrame.from_dict(json_[\"value\"]) # Fetch available dataset\n",
    "    print(f\" total Sentinel tiles found {len(p)}\")\n",
    "    if len(p)>0:\n",
    "        # Remove L2A and UTM50 dataset\n",
    "        p = p[~p[\"Name\"].str.contains(\"L2A\")] \n",
    "        p = p[~p[\"Name\"].str.contains(\"T50Q\")] \n",
    "        df = pd.read_csv(\"D:/WaterQuality/ImageInfo.csv\")\n",
    "        for i in range(len(p)):\n",
    "            url_id = p[\"Id\"].iloc[i]\n",
    "            download_name = p[\"Name\"].iloc[i].split(\".\")[0]\n",
    "            contentdate = p[\"ContentDate\"].iloc[i]\n",
    "            print(\"Start download: \"+str(i+1)+\"/\"+str(len(p))+\"; \"+download_name)\n",
    "            keycloak_token = get_keycloak()\n",
    "            url = f\"https://zipper.dataspace.copernicus.eu/odata/v1/Products(\"+url_id+\")/$value\"\n",
    "            headers = {\"Authorization\": f\"Bearer {keycloak_token}\"}\n",
    "            session = requests.Session()\n",
    "            session.headers.update(headers)\n",
    "            response = session.get(url, headers=headers, stream=True)\n",
    "            with open(\"D:/WaterQuality/datadownload/\"+download_name+\".zip\", \"wb\") as file:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    if chunk:\n",
    "                        file.write(chunk)\n",
    "            df.loc[len(df.index)] = [download_name, contentdate[\"Start\"]]\n",
    "            print(\"Finish download: \"+download_name)\n",
    "        df.to_csv(\"D:/WaterQuality/ImageInfo.csv\", index=False)\n",
    "\n",
    "# Function to preprocess a single Landsat image\n",
    "def preprocessLandsat(tar):\n",
    "    # extract tar\n",
    "    datadir = 'D:/WaterQuality/datadownload'\n",
    "    os.chdir(datadir)\n",
    "    file = tarfile.open(tar)\n",
    "    file.extractall('extract')\n",
    "    file.close()\n",
    "    # run acolite\n",
    "    acolitepath = \"D:/WaterQuality/acolite/acolite_py_win/dist/acolite/acolite.exe\"\n",
    "    settingpath = \"D:/WaterQuality/acolite/setting_landsat.txt\"\n",
    "    os.system(acolitepath+\" --cli --settings=\"+settingpath)\n",
    "    def merge_and_mask():\n",
    "        # merge 7 bands\n",
    "        os.chdir('atmocor')\n",
    "        tiflist = glob.glob('*L2R_rhos_*.tif')\n",
    "        bandorder = [2, 3, 4, 7, 8, 0, 1]\n",
    "        tiflist = [tiflist[i] for i in bandorder]\n",
    "        env.workspace = 'D:/WaterQuality/datadownload/atmocor'\n",
    "        arcpy.CompositeBands_management(tiflist, \"compbands.tif\")\n",
    "        # mask land and cloud\n",
    "        ras = Raster(\"compbands.tif\")\n",
    "        qaband = Raster(glob.glob(datadir+'/extract/*QA_PIXEL.TIF')[0])\n",
    "        qaband_m = SetNull(qaband>22200,1)\n",
    "        qaband_m = FocalStatistics(qaband_m, NbrCircle(3,\"CELL\"), \"MEAN\", \"NODATA\") # expand radius 3\n",
    "        ras_m = ExtractByMask(ras, qaband_m)\n",
    "        swir = Raster(\"compbands.tif\\Band_6\")\n",
    "        green = Raster(\"compbands.tif\\Band_3\")\n",
    "        nir = Raster(\"compbands.tif\\Band_5\")\n",
    "        red = Raster(\"compbands.tif\\Band_4\")\n",
    "        ndvi1 = arcpy.sa.Float((red-nir)/(red+nir))\n",
    "        ndvi1_m = SetNull(ndvi1<0,1)\n",
    "        ndwi = arcpy.sa.Float((green-swir)/(green+swir))\n",
    "        ndwi_m = SetNull(ndwi<0,1)\n",
    "        swir_m = SetNull(swir>0.15,1)\n",
    "        ras_m = ExtractByMask(ras_m, ndvi1_m)\n",
    "        ras_m = ExtractByMask(ras_m, ndwi_m)\n",
    "        ras_m = ExtractByMask(ras_m, swir_m)\n",
    "        # reproject\n",
    "        aoi = \"D:/WaterQuality/aoi/aoi.shp\"\n",
    "        outfilename = \"D:/WaterQuality/reflectance/\"+tar.replace(\".tar\",\".tif\")\n",
    "        arcpy.management.ProjectRaster(ras_m, \"compbands_p.tif\", aoi)            \n",
    "        arcpy.management.Clip(\"compbands_p.tif\", aoi, \"compbands_p_c.tif\",                                \n",
    "                            \"#\", \"#\", \"NONE\",\"MAINTAIN_EXTENT\")\n",
    "        arcpy.management.Resample(\"compbands_p_c.tif\", outfilename, 0.00028571429)\n",
    "    merge_and_mask()\n",
    "    # empty extract and atmocor\n",
    "    def emptyfolder(folder):\n",
    "        for filename in os.listdir(folder):\n",
    "            file_path = os.path.join(folder, filename)    \n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "    emptyfolder(\"D:/WaterQuality/datadownload/extract\")\n",
    "    emptyfolder(\"D:/WaterQuality/datadownload/atmocor\")\n",
    "    # delete tarfile\n",
    "    os.chdir(datadir)\n",
    "    os.unlink(tar)\n",
    "\n",
    "# Function to preprocess a single Sentinel image\n",
    "def preprocessSentinel(zipf):\n",
    "    datadir = 'D:/WaterQuality/datadownload'\n",
    "    os.chdir(datadir)\n",
    "    with zipfile.ZipFile(zipf, 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "    safefolder = glob.glob('*.SAFE')[0]\n",
    "    # run acolite\n",
    "    settingtemp = \"D:/WaterQuality/acolite/setting_sentinel.txt\"\n",
    "    settingpath = \"D:/WaterQuality/acolite/setting_sentinel2.txt\"\n",
    "    # Read in the file\n",
    "    with open(settingtemp, 'r') as file:\n",
    "        filedata = file.read()\n",
    "        filedata = filedata.replace('inputfile=', 'inputfile='+os.path.join(datadir,safefolder))\n",
    "    # Write the file out again\n",
    "    with open(settingpath, 'w') as file:\n",
    "        file.write(filedata)\n",
    "    acolitepath = \"D:/WaterQuality/acolite/acolite_py_win/dist/acolite/acolite.exe\"\n",
    "    os.system(acolitepath+\" --cli --settings=\"+settingpath)\n",
    "    def merge_and_mask():\n",
    "        # merge 7 bands\n",
    "        os.chdir('atmocor')\n",
    "        tiflist = glob.glob('*L2R_rhos_*.tif')\n",
    "        if len(tiflist)==0: # if acolite does not produce any files\n",
    "            return\n",
    "        bandorder = [2, 3, 4, 5, 10, 0, 1]\n",
    "        tiflist = [tiflist[i] for i in bandorder]\n",
    "        env.workspace = 'D:/WaterQuality/datadownload/atmocor'\n",
    "        arcpy.CompositeBands_management(tiflist, \"compbands.tif\")\n",
    "        arcpy.management.Resample(\"compbands.tif\", \"compbands_r.tif\", 30)\n",
    "        # mask land and cloud\n",
    "        ras = Raster(\"compbands_r.tif\")\n",
    "        swir = Raster(\"compbands_r.tif\\Band_6\")\n",
    "        green = Raster(\"compbands_r.tif\\Band_3\")\n",
    "        nir = Raster(\"compbands_r.tif\\Band_5\")\n",
    "        red = Raster(\"compbands_r.tif\\Band_4\")\n",
    "        cloud_m = SetNull((red>0.2)&(nir>0.2),1)\n",
    "        cloud_m = FocalStatistics(cloud_m, NbrCircle(3,\"CELL\"), \"MEAN\", \"NODATA\") # expand radius 3\n",
    "        ndvi1 = arcpy.sa.Float((red-nir)/(red+nir))\n",
    "        ndvi1_m = SetNull(ndvi1<0,1)\n",
    "        ndwi2 = arcpy.sa.Float((green-swir)/(green+swir))\n",
    "        ndwi2_m = SetNull(ndwi2<0,1)\n",
    "        swir_m = SetNull(swir>0.15,1)\n",
    "        nir_m = SetNull((nir>0.03)&(red>0.08)&(ndwi2_m==1)&(swir_m==1)&(cloud_m==1),1) # remaining haze\n",
    "        nir_m = FocalStatistics(nir_m, NbrCircle(1,\"CELL\"), \"MEAN\", \"NODATA\") # expand radius 1\n",
    "        ras_m = ExtractByMask(ras, cloud_m)\n",
    "        ras_m = ExtractByMask(ras_m, ndvi1_m)\n",
    "        ras_m = ExtractByMask(ras_m, ndwi2_m)\n",
    "        ras_m = ExtractByMask(ras_m, swir_m)\n",
    "        ras_m = ExtractByMask(ras_m, nir_m)\n",
    "        # reproject\n",
    "        aoi = \"D:/WaterQuality/aoi/aoi.shp\"\n",
    "        outfilename = \"D:/WaterQuality/reflectance/\"+safefolder.replace(\".SAFE\",\".tif\")\n",
    "        arcpy.management.ProjectRaster(ras_m, \"compbands_p.tif\", aoi)\n",
    "        arcpy.management.Clip(\"compbands_p.tif\", aoi, \"compbands_p_c.tif\",                                \n",
    "                            \"#\", \"#\", \"NONE\",\"MAINTAIN_EXTENT\")\n",
    "        arcpy.management.Resample(\"compbands_p_c.tif\", outfilename, 0.00028571429)\n",
    "    merge_and_mask()\n",
    "    # empty extract and atmocor\n",
    "    def emptyfolder(folder):\n",
    "        for filename in os.listdir(folder):\n",
    "            file_path = os.path.join(folder, filename)    \n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "    emptyfolder(\"D:/WaterQuality/datadownload/atmocor\")\n",
    "    # delete whole safefolder\n",
    "    os.chdir(datadir)\n",
    "    shutil.rmtree(safefolder)\n",
    "    os.unlink(zipf)\n",
    "\n",
    "# Function to preprocess all Landsat images\n",
    "def preprocessLandsat_all():\n",
    "    datadir = 'D:/WaterQuality/datadownload'\n",
    "    os.chdir(datadir)\n",
    "    tarlist = glob.glob('*.tar')\n",
    "    if len(tarlist)>0:\n",
    "        for tar in tarlist:\n",
    "            preprocessLandsat(tar)\n",
    "\n",
    "# Function to preprocess all Sentinel images\n",
    "def preprocessSentinel_all():\n",
    "    datadir = 'D:/WaterQuality/datadownload'\n",
    "    os.chdir(datadir)\n",
    "    ziplist = glob.glob('*.zip')\n",
    "    if len(ziplist)>0:\n",
    "        for zipf in ziplist:\n",
    "            preprocessSentinel(zipf)\n",
    "\n",
    "# Function to get dates in each month\n",
    "def monthstart(year, month):\n",
    "    from datetime import date, datetime, timedelta\n",
    "    first_date = datetime(year, month, 1)\n",
    "    return first_date.strftime(\"%Y-%m-%d\")\n",
    "def monthmid1(year, month):\n",
    "    from datetime import date, datetime, timedelta\n",
    "    mid_date = datetime(year, month, 15)\n",
    "    return mid_date.strftime(\"%Y-%m-%d\")\n",
    "def monthmid2(year, month):\n",
    "    from datetime import date, datetime, timedelta\n",
    "    mid_date = datetime(year, month, 16)\n",
    "    return mid_date.strftime(\"%Y-%m-%d\")\n",
    "def monthend(year, month):\n",
    "    from datetime import date, datetime, timedelta\n",
    "    if month == 12:\n",
    "        last_date = datetime(year, month, 31)\n",
    "    else:\n",
    "        last_date = datetime(year, month + 1, 1) + timedelta(days=-1)\n",
    "    return last_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Remove Tier 2 Landsat imagery\n",
    "def removeLandsatT2():\n",
    "    os.chdir(\"D:/WaterQuality/reflectance\")\n",
    "    Tier2list = glob.glob('LC*T2.*')\n",
    "    if len(Tier2list)>0:\n",
    "        for T2file in Tier2list:\n",
    "            os.unlink(T2file)\n",
    "\n",
    "# Rename all Landsat imagery\n",
    "def renameLandsat_all():\n",
    "    os.chdir(\"D:/WaterQuality/reflectance\")\n",
    "    Landsatlist = glob.glob('LC*')\n",
    "    for Landsatfile in Landsatlist:\n",
    "        nfilename = Landsatfile[0:25]+Landsatfile[40:] # first 25 characters & from 40 to end\n",
    "        os.rename(Landsatfile, nfilename)\n",
    "\n",
    "# Rename all Sentinel imagery\n",
    "def renameSentinel_all():\n",
    "    os.chdir(\"D:/WaterQuality/reflectance\")\n",
    "    Sentinellist = glob.glob('S2*')\n",
    "    for Sentinelfile in Sentinellist:\n",
    "        nfilename = Sentinelfile[0:19]+Sentinelfile[37:44]+Sentinelfile[60:]\n",
    "        if os.path.isfile(nfilename) == True:\n",
    "            nfilename = Sentinelfile[0:19]+Sentinelfile[37:44]+'a'+Sentinelfile[60:]\n",
    "        os.rename(Sentinelfile, nfilename)\n",
    "\n",
    "# Mosaic tiles acquired on the same day\n",
    "def mosaictiles(): \n",
    "    os.chdir(\"D:/WaterQuality/reflectance\")\n",
    "    env.workspace = \"D:/WaterQuality/reflectance\"\n",
    "    Landsatlist = glob.glob('LC*')\n",
    "    Landsatdatelist = [i[17:25] for i in Landsatlist]\n",
    "    Sentinellist = glob.glob('S2*')\n",
    "    Sentineldatelist = [i[11:19] for i in Sentinellist]\n",
    "    datelist = sorted(list(set(Landsatdatelist+Sentineldatelist))) # get unique date\n",
    "    imglist = glob.glob('*.tif')\n",
    "    for d in datelist:\n",
    "        img_match = [img for img in imglist if d in img]\n",
    "        outfolder = \"D:/WaterQuality/preprocess_finish\"\n",
    "        outfilename = \"LandsatSentinel_\"+d+\".tif\"\n",
    "        if len(img_match)==1:\n",
    "            arcpy.management.CopyRaster(img_match[0], os.path.join(outfolder, outfilename))\n",
    "            arcpy.management.Delete(img_match[0]) # delete original file in reflectance folder\n",
    "        if len(img_match)>1:\n",
    "            arcpy.MosaicToNewRaster_management(img_match,outfolder,outfilename,\"\",\"32_BIT_FLOAT\",\"\",\"7\",\"MEAN\",\"\")\n",
    "            arcpy.management.Delete(img_match) # delete original file in reflectance folder\n",
    "        # deleteimage_lowvalid\n",
    "        img1 = os.path.join(outfolder, outfilename)\n",
    "        ras_np = arcpy.RasterToNumPyArray(img1,\"\",\"\",\"\",-9999)[0]\n",
    "        if (ras_np != -9999).sum() < (2390000*0.1): # largest valid count = 2390000\n",
    "            arcpy.management.Delete(img1)\n",
    "\n",
    "# Connect all functions\n",
    "def download_preprocess_allimagery(startdate, enddate): # From search download to mosaic\n",
    "    print(\"Start download Landsat\")\n",
    "    downloadlandsat(startdate, enddate)\n",
    "    print(\"Start download Sentinel\")\n",
    "    downloadsentinel(startdate, enddate)\n",
    "    print(\"Start preprocess Landsat\")\n",
    "    preprocessLandsat_all()\n",
    "    print(\"Start preprocess Sentinel\")\n",
    "    preprocessSentinel_all()\n",
    "    removeLandsatT2()\n",
    "    renameLandsat_all()\n",
    "    renameSentinel_all()\n",
    "    print(\"Start mosaic\")\n",
    "    mosaictiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function from search download to mosaic\n",
    "# download_preprocess_allimagery(startdate, enddate)\n",
    "download_preprocess_allimagery(\"2024-07-10\", \"2024-07-10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict Chla\n",
    "def predictChla(imgname): # name with full path\n",
    "\toutfolder = \"D:/WaterQuality/predict\"\n",
    "\tos.chdir(outfolder)\n",
    "\tenv.workspace = outfolder\n",
    "\t# ANN layers: 14, 6, 3, 1\n",
    "\tp = pd.read_json(\"D:/WaterQuality/extract/Chla_modelweight.json\", typ=\"series\")\n",
    "\t# Chla ['NR_B2B4', 'NR_B2B6', 'NR_B3B6', 'NR_B3B4', 'TB_B1B2B3', \n",
    "\t# 'TB_B4B5B6', 'B2_3', 'B5', 'B4_2', 'B3_3', 'TB_B2B3B4', 'B6_3', 'NR_B1B6', 'B6_2']\n",
    "\toutname = imgname.replace(\"preprocess_finish\", \"predict\").replace(\"LandsatSentinel_20\", \"Chla_20\")\n",
    "\tb1 = Raster(imgname+\"/Band_1\")*10\n",
    "\tb2 = Raster(imgname+\"/Band_2\")*10\n",
    "\tb3 = Raster(imgname+\"/Band_3\")*10\n",
    "\tb4 = Raster(imgname+\"/Band_4\")*10\n",
    "\tb5 = Raster(imgname+\"/Band_5\")*10\n",
    "\tb6 = Raster(imgname+\"/Band_6\")*10\n",
    "\tras_0 = b1*0\n",
    "\tras_neg1 = ras_0 - 1\n",
    "\tras_1 = ras_0 + 1\n",
    "\tv1 = CellStatistics([CellStatistics([(b2-b4)/(b2+b4),ras_neg1], \"MAXIMUM\"),ras_1],\"MINIMUM\")\n",
    "\tv2 = CellStatistics([CellStatistics([(b2-b6)/(b2+b6),ras_neg1], \"MAXIMUM\"),ras_1],\"MINIMUM\")\n",
    "\tv3 = CellStatistics([CellStatistics([(b3-b6)/(b3+b6),ras_neg1], \"MAXIMUM\"),ras_1],\"MINIMUM\")\n",
    "\tv4 = CellStatistics([CellStatistics([(b3-b4)/(b3+b4),ras_neg1], \"MAXIMUM\"),ras_1],\"MINIMUM\")\n",
    "\tv5 = CellStatistics([CellStatistics([(((1/b1)-(1/b2))*b3),ras_neg1], \"MAXIMUM\"),ras_1],\"MINIMUM\")\n",
    "\tv6 = CellStatistics([CellStatistics([(((1/b4)-(1/b5))*b6),ras_neg1], \"MAXIMUM\"),ras_1],\"MINIMUM\")\n",
    "\tv7 = b2 ** 3\n",
    "\tv8 = b5\n",
    "\tv9 = b4 ** 2\n",
    "\tv10 = b3 ** 3\n",
    "\tv11 = CellStatistics([CellStatistics([(((1/b2)-(1/b3))*b4),ras_neg1], \"MAXIMUM\"),ras_1],\"MINIMUM\")\n",
    "\tv12 = b6 ** 3\n",
    "\tv13 = CellStatistics([CellStatistics([(b1-b6)/(b1+b6),ras_neg1], \"MAXIMUM\"),ras_1],\"MINIMUM\")\n",
    "\tv14 = b6 ** 2\n",
    "\n",
    "\th1n1 = (Exp((p[1][0]+v1*p[0][0][0]+v2*p[0][1][0]+v3*p[0][2][0]+v4*p[0][3][0]+v5*p[0][4][0]+\n",
    "\t\t\tv6*p[0][5][0]+v7*p[0][6][0]+v8*p[0][7][0]+v9*p[0][8][0]+v10*p[0][9][0]+\n",
    "\t\t\tv11*p[0][10][0]+v12*p[0][11][0]+v13*p[0][12][0]+v14*p[0][13][0])*(-1))+1)**-1\n",
    "\th1n2 = (Exp((p[1][1]+v1*p[0][0][1]+v2*p[0][1][1]+v3*p[0][2][1]+v4*p[0][3][1]+v5*p[0][4][1]+\n",
    "\t\t\tv6*p[0][5][1]+v7*p[0][6][1]+v8*p[0][7][1]+v9*p[0][8][1]+v10*p[0][9][1]+\n",
    "\t\t\tv11*p[0][10][1]+v12*p[0][11][1]+v13*p[0][12][1]+v14*p[0][13][1])*(-1))+1)**-1\n",
    "\th1n3 = (Exp((p[1][2]+v1*p[0][0][2]+v2*p[0][1][2]+v3*p[0][2][2]+v4*p[0][3][2]+v5*p[0][4][2]+\n",
    "\t\t\tv6*p[0][5][2]+v7*p[0][6][2]+v8*p[0][7][2]+v9*p[0][8][2]+v10*p[0][9][2]+\n",
    "\t\t\tv11*p[0][10][2]+v12*p[0][11][2]+v13*p[0][12][2]+v14*p[0][13][2])*(-1))+1)**-1\n",
    "\th1n4 = (Exp((p[1][3]+v1*p[0][0][3]+v2*p[0][1][3]+v3*p[0][2][3]+v4*p[0][3][3]+v5*p[0][4][3]+\n",
    "\t\t\tv6*p[0][5][3]+v7*p[0][6][3]+v8*p[0][7][3]+v9*p[0][8][3]+v10*p[0][9][3]+\n",
    "\t\t\tv11*p[0][10][3]+v12*p[0][11][3]+v13*p[0][12][3]+v14*p[0][13][3])*(-1))+1)**-1\n",
    "\th1n5 = (Exp((p[1][4]+v1*p[0][0][4]+v2*p[0][1][4]+v3*p[0][2][4]+v4*p[0][3][4]+v5*p[0][4][4]+\n",
    "\t\t\tv6*p[0][5][4]+v7*p[0][6][4]+v8*p[0][7][4]+v9*p[0][8][4]+v10*p[0][9][4]+\n",
    "\t\t\tv11*p[0][10][4]+v12*p[0][11][4]+v13*p[0][12][4]+v14*p[0][13][4])*(-1))+1)**-1\n",
    "\th1n6 = (Exp((p[1][5]+v1*p[0][0][5]+v2*p[0][1][5]+v3*p[0][2][5]+v4*p[0][3][5]+v5*p[0][4][5]+\n",
    "\t\t\tv6*p[0][5][5]+v7*p[0][6][5]+v8*p[0][7][5]+v9*p[0][8][5]+v10*p[0][9][5]+\n",
    "\t\t\tv11*p[0][10][5]+v12*p[0][11][5]+v13*p[0][12][5]+v14*p[0][13][5])*(-1))+1)**-1\n",
    "\n",
    "\th2n1 = (Exp((p[3][0]+h1n1*p[2][0][0]+h1n2*p[2][1][0]+h1n3*p[2][2][0]+\n",
    "\t\t\th1n4*p[2][3][0]+h1n5*p[2][4][0]+h1n6*p[2][5][0])*(-1))+1)**-1\n",
    "\th2n2 = (Exp((p[3][1]+h1n1*p[2][0][1]+h1n2*p[2][1][1]+h1n3*p[2][2][1]+\n",
    "\t\t\th1n4*p[2][3][1]+h1n5*p[2][4][1]+h1n6*p[2][5][1])*(-1))+1)**-1\n",
    "\th2n3 = (Exp((p[3][2]+h1n1*p[2][0][2]+h1n2*p[2][1][2]+h1n3*p[2][2][2]+\n",
    "\t\t\th1n4*p[2][3][2]+h1n5*p[2][4][2]+h1n6*p[2][5][2])*(-1))+1)**-1\n",
    "\n",
    "\tpred = CellStatistics([p[5][0]+h2n1*p[4][0][0]+h2n2*p[4][1][0]+h2n3*p[4][2][0],ras_0], \"MAXIMUM\")\n",
    "\tarcpy.management.CopyRaster(pred, outname)\n",
    "\n",
    "# predict SS\n",
    "def predictSS(imgname):\n",
    "\toutfolder = \"D:/WaterQuality/predict\"\n",
    "\tos.chdir(outfolder)\n",
    "\tenv.workspace = outfolder\n",
    "\t# ANN layers: 9, 6, 3, 1\n",
    "\tp = pd.read_json(\"D:/WaterQuality/extract/SS_modelweight.json\", typ=\"series\")\n",
    "\t# SS ['TB_B2B3B4', 'LH_B4B5B6', 'B3_3', 'B4_2', 'LH_B5B6B7', 'TB_B3B4B5', 'NR_B5B6', 'NR_B1B4', 'B2_3']\n",
    "\toutname = imgname.replace(\"preprocess_finish\", \"predict\").replace(\"LandsatSentinel_20\", \"SuSo_20\")\n",
    "\tb1 = Raster(imgname+\"/Band_1\")*10\n",
    "\tb2 = Raster(imgname+\"/Band_2\")*10\n",
    "\tb3 = Raster(imgname+\"/Band_3\")*10\n",
    "\tb4 = Raster(imgname+\"/Band_4\")*10\n",
    "\tb5 = Raster(imgname+\"/Band_5\")*10\n",
    "\tb6 = Raster(imgname+\"/Band_6\")*10\n",
    "\tb7 = Raster(imgname+\"/Band_7\")*10\n",
    "\tras_0 = b1*0\n",
    "\tras_neg1 = ras_0 - 1\n",
    "\tras_1 = ras_0 + 1\n",
    "\tv1 = CellStatistics([CellStatistics([(((1/b2)-(1/b3))*b4),ras_neg1], \"MAXIMUM\"),ras_1],\"MINIMUM\")\n",
    "\tv2 = b5-b4-((b6-b4)*((865-660)/(1610-660)))\n",
    "\tv3 = b3 ** 3\n",
    "\tv4 = b4 ** 2\n",
    "\tv5 = b6-b5-((b7-b5)*((1610-865)/(2195-865)))\n",
    "\tv6 = CellStatistics([CellStatistics([(((1/b3)-(1/b4))*b5),ras_neg1], \"MAXIMUM\"),ras_1],\"MINIMUM\")\n",
    "\tv7 = CellStatistics([CellStatistics([(b5-b6)/(b5+b6),ras_neg1], \"MAXIMUM\"),ras_1],\"MINIMUM\")\n",
    "\tv8 = CellStatistics([CellStatistics([(b1-b4)/(b1+b4),ras_neg1], \"MAXIMUM\"),ras_1],\"MINIMUM\")\n",
    "\tv9 = b2 ** 3\n",
    "\n",
    "\th1n1 = (Exp((p[1][0]+v1*p[0][0][0]+v2*p[0][1][0]+v3*p[0][2][0]+v4*p[0][3][0]+v5*p[0][4][0]+\n",
    "\t\t\tv6*p[0][5][0]+v7*p[0][6][0]+v8*p[0][7][0]+v9*p[0][8][0])*(-1))+1)**-1\n",
    "\th1n2 = (Exp((p[1][1]+v1*p[0][0][1]+v2*p[0][1][1]+v3*p[0][2][1]+v4*p[0][3][1]+v5*p[0][4][1]+\n",
    "\t\t\tv6*p[0][5][1]+v7*p[0][6][1]+v8*p[0][7][1]+v9*p[0][8][1])*(-1))+1)**-1\n",
    "\th1n3 = (Exp((p[1][2]+v1*p[0][0][2]+v2*p[0][1][2]+v3*p[0][2][2]+v4*p[0][3][2]+v5*p[0][4][2]+\n",
    "\t\t\tv6*p[0][5][2]+v7*p[0][6][2]+v8*p[0][7][2]+v9*p[0][8][2])*(-1))+1)**-1\n",
    "\th1n4 = (Exp((p[1][3]+v1*p[0][0][3]+v2*p[0][1][3]+v3*p[0][2][3]+v4*p[0][3][3]+v5*p[0][4][3]+\n",
    "\t\t\tv6*p[0][5][3]+v7*p[0][6][3]+v8*p[0][7][3]+v9*p[0][8][3])*(-1))+1)**-1\n",
    "\th1n5 = (Exp((p[1][4]+v1*p[0][0][4]+v2*p[0][1][4]+v3*p[0][2][4]+v4*p[0][3][4]+v5*p[0][4][4]+\n",
    "\t\t\tv6*p[0][5][4]+v7*p[0][6][4]+v8*p[0][7][4]+v9*p[0][8][4])*(-1))+1)**-1\n",
    "\th1n6 = (Exp((p[1][5]+v1*p[0][0][5]+v2*p[0][1][5]+v3*p[0][2][5]+v4*p[0][3][5]+v5*p[0][4][5]+\n",
    "\t\t\tv6*p[0][5][5]+v7*p[0][6][5]+v8*p[0][7][5]+v9*p[0][8][5])*(-1))+1)**-1\n",
    "\n",
    "\th2n1 = (Exp((p[3][0]+h1n1*p[2][0][0]+h1n2*p[2][1][0]+h1n3*p[2][2][0]+\n",
    "\t\t\th1n4*p[2][3][0]+h1n5*p[2][4][0]+h1n6*p[2][5][0])*(-1))+1)**-1\n",
    "\th2n2 = (Exp((p[3][1]+h1n1*p[2][0][1]+h1n2*p[2][1][1]+h1n3*p[2][2][1]+\n",
    "\t\t\th1n4*p[2][3][1]+h1n5*p[2][4][1]+h1n6*p[2][5][1])*(-1))+1)**-1\n",
    "\th2n3 = (Exp((p[3][2]+h1n1*p[2][0][2]+h1n2*p[2][1][2]+h1n3*p[2][2][2]+\n",
    "\t\t\th1n4*p[2][3][2]+h1n5*p[2][4][2]+h1n6*p[2][5][2])*(-1))+1)**-1\n",
    "\n",
    "\tpred = CellStatistics([p[5][0]+h2n1*p[4][0][0]+h2n2*p[4][1][0]+h2n3*p[4][2][0],ras_0], \"MAXIMUM\")\n",
    "\tarcpy.management.CopyRaster(pred, outname)\n",
    "\n",
    "def predict_ChlaSS_all():\n",
    "    imglist = glob.glob('D:/WaterQuality/preprocess_finish/*.tif')\n",
    "    for i in imglist:\n",
    "        predictChla(i)\n",
    "        predictSS(i)\n",
    "        # move img to finish folder\n",
    "        imgname_move = i.replace(\"preprocess_finish\", \"preprocess_finish/finish\")\n",
    "        arcpy.management.CopyRaster(i, imgname_move)\n",
    "        arcpy.management.Delete(i)\n",
    "\n",
    "# update predicted latestimg\n",
    "def update_latestimg():\n",
    "    aoi_water = \"D:/WaterQuality/aoi/aoi_water.shp\"\n",
    "    # Chla\n",
    "    oldimg = glob.glob(\"D:/WaterQuality/predict_display/merge_Chla_*.tif\")[0]\n",
    "    chlalist = glob.glob(\"D:/WaterQuality/predict/Chla_*.tif\")\n",
    "    latestimg = chlalist[len(chlalist)-1]\n",
    "    latestimg = latestimg[len(latestimg)-17:len(latestimg)]\n",
    "    mergeras = arcpy.management.MosaicToNewRaster([oldimg]+chlalist, \"D:/WaterQuality/predict_display\", \"merge_\"+latestimg, \"\", \"32_BIT_FLOAT\", \"\", 1, \"LAST\")\n",
    "    mergeras_focal = FocalStatistics(mergeras, NbrRectangle(3,3,\"CELL\"), \"MEDIAN\")\n",
    "    outname = (\"D:/WaterQuality/predict_display/merge_\"+latestimg).replace(\".tif\", \"_smoothclip.tif\")\n",
    "    arcpy.management.Clip(mergeras_focal, \"\", outname, aoi_water, \"\", \"ClippingGeometry\")\n",
    "    arcpy.management.Delete(oldimg)\n",
    "    arcpy.management.Delete(oldimg.replace(\".tif\", \"_smoothclip.tif\"))\n",
    "    # SS\n",
    "    oldimg = glob.glob(\"D:/WaterQuality/predict_display/merge_SuSo_*.tif\")[0]\n",
    "    sslist = glob.glob(\"D:/WaterQuality/predict/SuSo_*.tif\")\n",
    "    latestimg = sslist[len(sslist)-1]\n",
    "    latestimg = latestimg[len(latestimg)-17:len(latestimg)]\n",
    "    mergeras = arcpy.management.MosaicToNewRaster([oldimg]+sslist, \"D:/WaterQuality/predict_display\", \"merge_\"+latestimg, \"\", \"32_BIT_FLOAT\", \"\", 1, \"LAST\")\n",
    "    mergeras_focal = FocalStatistics(mergeras, NbrRectangle(3,3,\"CELL\"), \"MEDIAN\")\n",
    "    outname = (\"D:/WaterQuality/predict_display/merge_\"+latestimg).replace(\".tif\", \"_smoothclip.tif\")\n",
    "    arcpy.management.Clip(mergeras_focal, \"\", outname, aoi_water, \"\", \"ClippingGeometry\")\n",
    "    arcpy.management.Delete(oldimg)\n",
    "    arcpy.management.Delete(oldimg.replace(\".tif\", \"_smoothclip.tif\"))\n",
    "\n",
    "# update datapoint to latest date\n",
    "def update_datapoint():\n",
    "    datapoint = \"D:/WaterQuality/ArcGISPro/DataPoint.shp\"\n",
    "    datapoint_d1 = \"D:/WaterQuality/ArcGISPro/DataPoint_d1.shp\"\n",
    "    datapoint_d2 = \"D:/WaterQuality/ArcGISPro/DataPoint_d2.shp\"\n",
    "    datapoint_all = \"D:/WaterQuality/ArcGISPro/DataPoint_all.shp\"\n",
    "    chlalist = glob.glob(\"D:/WaterQuality/predict/Chla_*.tif\")\n",
    "    sslist = glob.glob(\"D:/WaterQuality/predict/SuSo_*.tif\")\n",
    "    for i in range(0,len(chlalist)):\n",
    "        chla_d1 = chlalist[i]\n",
    "        ss_d1 = sslist[i]\n",
    "        arcpy.management.Copy(datapoint, datapoint_d1)\n",
    "        arcpy.management.Copy(datapoint, datapoint_d2)\n",
    "        arcpy.sa.ExtractMultiValuesToPoints(datapoint_d1, chla_d1+\" value\", \"BILINEAR\")\n",
    "        arcpy.sa.ExtractMultiValuesToPoints(datapoint_d2, ss_d1+\" value\", \"BILINEAR\")\n",
    "        # remove points with no data, else add date and extract list of valid points\n",
    "        newdatapt = []\n",
    "        d1 = int(chla_d1[len(chla_d1)-12:len(chla_d1)-4])\n",
    "        d1_month = round(d1/100)*100+15\n",
    "        with arcpy.da.UpdateCursor(datapoint_d1, [\"value\",\"pt\",\"Date\",\"parameter\",\"latest\",\"DateRange\"]) as cursor:\n",
    "            for row in cursor:\n",
    "                if row[0] < 0:\n",
    "                    cursor.deleteRow()\n",
    "                else:\n",
    "                    newdatapt.append(row[1])\n",
    "                    row[2] = d1 # Date\n",
    "                    row[3] = \"Chla\"\n",
    "                    row[4] = 1 # latest\n",
    "                    row[5] = \"Day\"\n",
    "                    cursor.updateRow(row)\n",
    "        # modify values for SS\n",
    "        with arcpy.da.UpdateCursor(datapoint_d2, [\"value\",\"pt\",\"Date\",\"parameter\",\"latest\",\"DateRange\"]) as cursor:\n",
    "            for row in cursor:\n",
    "                if row[0] < 0:\n",
    "                    cursor.deleteRow()\n",
    "                else:\n",
    "                    row[2] = d1 # Date\n",
    "                    row[3] = \"SS\"\n",
    "                    row[4] = 1 # latest\n",
    "                    row[5] = \"Day\"\n",
    "                    cursor.updateRow(row)    \n",
    "        # modify latest in datapoint_all\n",
    "        with arcpy.da.UpdateCursor(datapoint_all, [\"pt\",\"latest\",\"Date\",\"DateRange\"], \"latest = 1\") as cursor: # where clause\n",
    "            for row in cursor:\n",
    "                if row[0] in newdatapt: # if latest image provides obs on this pt\n",
    "                    row[1] = 0\n",
    "                    if row[3]==\"Month\" and row[2]==d1_month: # if same month as latest image\n",
    "                        row[1] = 1\n",
    "                    cursor.updateRow(row)\n",
    "        arcpy.management.Append(datapoint_d1, datapoint_all)\n",
    "        arcpy.management.Append(datapoint_d2, datapoint_all)\n",
    "        # add monthly average data\n",
    "        with arcpy.da.UpdateCursor(datapoint_d1, [\"Date\",\"DateRange\"]) as cursor:\n",
    "            for row in cursor:\n",
    "                row[0] = d1_month\n",
    "                row[1] = \"Month\"\n",
    "                cursor.updateRow(row)\n",
    "        with arcpy.da.UpdateCursor(datapoint_d2, [\"Date\",\"DateRange\"]) as cursor:\n",
    "            for row in cursor:\n",
    "                row[0] = d1_month\n",
    "                row[1] = \"Month\"\n",
    "                cursor.updateRow(row)\n",
    "        arcpy.management.Append(datapoint_d1, datapoint_all)\n",
    "        arcpy.management.Append(datapoint_d2, datapoint_all)\n",
    "        arcpy.management.Delete(datapoint_d1)\n",
    "        arcpy.management.Delete(datapoint_d2)\n",
    "        # move chla and SS tif to finish\n",
    "        arcpy.management.CopyRaster(chla_d1, chla_d1.replace(\"predict\", \"predict/finish\"))\n",
    "        arcpy.management.Delete(chla_d1)\n",
    "        arcpy.management.CopyRaster(ss_d1, ss_d1.replace(\"predict\", \"predict/finish\"))\n",
    "        arcpy.management.Delete(ss_d1)\n",
    "        print(\"Finish: \"+ str(i+1)+\"/\"+str(len(chlalist)))\n",
    "    # save shp as zip file\n",
    "    os.chdir(\"D:/WaterQuality/ArcGISPro\")\n",
    "    datapoint_all_new = glob.glob(\"DataPoint_all.*\")\n",
    "    zipname = 'DataPoint_all_shp_to'+str(d1)+'.zip'\n",
    "    with zipfile.ZipFile(zipname, 'w') as zip_object:\n",
    "        for f in datapoint_all_new:\n",
    "            zip_object.write(f, compress_type=zipfile.ZIP_DEFLATED)\n",
    "    return zipname\n",
    "# zipname = update_datapoint()\n",
    "\n",
    "# Function to create kmz file for ArcGIS Online display\n",
    "def createkmz():\n",
    "    chlalayer = glob.glob(\"D:/WaterQuality/predict_display/merge_Chla_*_smoothclip.tif\")[0]\n",
    "    chlasym = \"D:/WaterQuality/ArcGISPro/chla_lyr.lyrx\"\n",
    "    chlalayer_sym = arcpy.management.ApplySymbologyFromLayer(chlalayer, chlasym)\n",
    "    os.unlink(\"D:/WaterQuality/ArcGISPro/chla_kmz.kmz\")\n",
    "    arcpy.conversion.LayerToKML(chlalayer_sym, \n",
    "                                \"D:/WaterQuality/ArcGISPro/chla_kmz.kmz\", 0, \"NO_COMPOSITE\", \n",
    "                                '113.81800000012 22.1377142789301 114.50171429609 22.5711428568601 GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]]', \n",
    "                                4096, 96, \"CLAMPED_TO_GROUND\")\n",
    "    sslayer = glob.glob(\"D:/WaterQuality/predict_display/merge_SuSo_*_smoothclip.tif\")[0]\n",
    "    sssym = \"D:/WaterQuality/ArcGISPro/ss_lyr.lyrx\"\n",
    "    sslayer_sym = arcpy.management.ApplySymbologyFromLayer(sslayer, sssym)\n",
    "    os.unlink(\"D:/WaterQuality/ArcGISPro/ss_kmz.kmz\")\n",
    "    arcpy.conversion.LayerToKML(sslayer_sym, \n",
    "                                \"D:/WaterQuality/ArcGISPro/ss_kmz.kmz\", 0, \"NO_COMPOSITE\", \n",
    "                                '113.81800000012 22.1377142789301 114.50171429609 22.5711428568601 GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]]', \n",
    "                                4096, 96, \"CLAMPED_TO_GROUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the functions to predict and update datapoints\n",
    "predict_ChlaSS_all()\n",
    "update_latestimg()\n",
    "zipname = update_datapoint()\n",
    "print(zipname)\n",
    "createkmz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload results to ArcGIS Online\n",
    "import os\n",
    "from arcgis.gis import GIS\n",
    "from arcgis.features import FeatureLayerCollection\n",
    "gis = GIS(url=\"https://wwww.arcgis.com\", username=\"username\", password=\"password\")  # Change to your ArcGIS Online account with publisher role\n",
    "# Data point FeatureLayer and shp\n",
    "DataPoint_all_shp_flc = gis.content.get(\"item id\")  # Item id of the datapoint featre layer collection on AGOL\n",
    "flc = FeatureLayerCollection.fromitem(DataPoint_all_shp_flc)\n",
    "flc.manager.overwrite(os.path.join(\"D:/WaterQuality/ArcGISPro\",zipname))\n",
    "DataPoint_all_shp_s = gis.content.get(\"item id\")  # Item id of the datapoint service on AGOL\n",
    "DataPoint_all_shp_s.update(data=os.path.join(\"D:/WaterQuality/ArcGISPro\",zipname))\n",
    "# kmz\n",
    "chla_kmz = gis.content.get(\"item id\")  # Item id of the chla kmz on AGOL\n",
    "chla_kmz.update(data=\"D:/WaterQuality/ArcGISPro/chla_kmz.kmz\")\n",
    "ss_kmz = gis.content.get(\"item id\")  # Item id of the SS kmz on AGOL\n",
    "ss_kmz.update(data=\"D:/WaterQuality/ArcGISPro/ss_kmz.kmz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
